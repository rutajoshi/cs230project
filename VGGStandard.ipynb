{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Import modules'''\n",
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "import math\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping,Callback,CSVLogger\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers.pooling import GlobalMaxPooling2D,GlobalAveragePooling2D\n",
    "from VGG16_sequential import VGG16\n",
    "from data_generator import load_data_generator\n",
    "\n",
    "from test import run_eval\n",
    "\n",
    "WIDTH = 224\n",
    "BATCH_SIZE = 128\n",
    "NB_EPOCH = 50\n",
    "LEARNING_RATE = 1e-04\n",
    "PATIENCE=4\n",
    "BN=True\n",
    "layer_nb=24\n",
    "optim='adadelta'\n",
    "\n",
    "ROOTPATH=sys.argv[1]\n",
    "train_txt = sys.argv[2]\n",
    "test_txt = sys.argv[3]\n",
    "LOW_DIM = int(sys.argv[4])\n",
    "ssRatio = 1.0  # float(sys.argv[3])/100.0\n",
    "PB_FLAG = sys.argv[5]  # to modify according to the task\n",
    "idOar=sys.argv[6]\n",
    "nbPop=0\n",
    "dropoutConf=0\n",
    "pool=None\n",
    "BNBA=False\n",
    "epochLength=-1\n",
    "\n",
    "print(sys.argv)\n",
    "\n",
    "for idarg,arg in enumerate(sys.argv):\n",
    "    if arg=='-bn':\n",
    "        BN=True\n",
    "    if arg=='-bnba':\n",
    "        BN=True\n",
    "        BNBA=True\n",
    "    if arg=='-nbn':\n",
    "        BN=False\n",
    "\n",
    "    elif arg=='-ft':\n",
    "        nbBlock=int(sys.argv[idarg+1])\n",
    "        if nbBlock==0:\n",
    "            layer_nb=30\n",
    "        elif nbBlock==1:\n",
    "            layer_nb=24\n",
    "        elif nbBlock==2:\n",
    "            layer_nb=16\n",
    "        elif nbBlock==3:\n",
    "            layer_nb=8\n",
    "\n",
    "    elif arg=='-bs':\n",
    "        batch_size= int(sys.argv[idarg+1])\n",
    "    elif arg=='-opt':\n",
    "        optim=sys.argv[idarg+1]\n",
    "        if optim==\"sgd\":\n",
    "            LEARNING_RATE=float(sys.argv[idarg+2])\n",
    "            optim = SGD(lr=LEARNING_RATE)\n",
    "            print(\"LR \" + str(LEARNING_RATE))\n",
    "\n",
    "    elif arg=='-lr':\n",
    "        LEARNING_RATE=float(sys.argv[idarg+1])\n",
    "    elif arg=='-rf':\n",
    "        if sys.argv[idarg+1]==\"conv\":\n",
    "            nbPop=3\n",
    "        elif sys.argv[idarg+1]==\"fc1\":\n",
    "            nbPop=2\n",
    "    elif arg=='-do':\n",
    "        dropoutConf=float(sys.argv[idarg+1])\n",
    "    elif arg=='-pool':\n",
    "        pool=sys.argv[idarg+1]\n",
    "        \n",
    "    if arg=='-el':\n",
    "        epochLength=int(sys.argv[idarg+1])\n",
    "    if arg=='-p':\n",
    "        PATIENCE=int(sys.argv[idarg+1])\n",
    "\n",
    "        \n",
    "print(optim)\n",
    "            \n",
    "class L2Model:\n",
    "    ''' Class of forward model'''\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "\n",
    "        self.network = VGG16(weights='imagenet')\n",
    "\n",
    "\n",
    "    def fit(self, (generator_training, n_train), (generator_val, n_val)):\n",
    "        '''Trains the model for a fixed number of epochs and iterations.\n",
    "           # Arguments\n",
    "                X_train: input data, as a Numpy array or list of Numpy arrays\n",
    "                    (if the model has multiple inputs).\n",
    "                Y_train : labels, as a Numpy array.\n",
    "                batch_size: integer. Number of samples per gradient update.\n",
    "                learning_rate: float, learning rate\n",
    "                nb_epoch: integer, the number of epochs to train the model.\n",
    "                validation_split: float (0. < x < 1).\n",
    "                    Fraction of the data to use as held-out validation data.\n",
    "                validation_data: tuple (x_val, y_val) or tuple\n",
    "                    (x_val, y_val, val_sample_weights) to be used as held-out\n",
    "                    validation data. Will override validation_split.\n",
    "                it: integer, number of iterations of the algorithm\n",
    "                \n",
    "            # Returns\n",
    "                A `History` object. Its `History.history` attribute is\n",
    "                a record of training loss values and metrics values\n",
    "                at successive epochs, as well as validation loss values\n",
    "                and validation metrics values (if applicable).\n",
    "            '''\n",
    "\n",
    "        if pool is None:\n",
    "            for pop in range(nbPop):\n",
    "                self.network.pop()\n",
    "                \n",
    "\n",
    "            if dropoutConf==-1:\n",
    "                self.network.layers[-2].rate=0.0\n",
    "            elif dropoutConf==1:\n",
    "                self.network.add(Dropout(0.5))\n",
    "            elif dropoutConf==2:\n",
    "                self.network.layers[-2].rate=0.0\n",
    "                self.network.add(Dropout(0.5))\n",
    "\n",
    "                \n",
    "        else:\n",
    "            for pop in range(4):\n",
    "                self.network.pop()\n",
    "            if pool==\"max\":\n",
    "                self.network.add(GlobalMaxPooling2D())\n",
    "            elif pool==\"avg\":\n",
    "                self.network.add(GlobalAveragePooling2D())\n",
    "            else:\n",
    "                print(\"ERROR: pooling not valide\")\n",
    "                exit(-1)\n",
    "\n",
    "\n",
    "                \n",
    "        if BNBA:\n",
    "            self.network.layers[-1].activation=Activation('linear')\n",
    "            self.network.add(BatchNormalization())\n",
    "            self.network.add(Activation('relu'))\n",
    "        elif BN:\n",
    "\n",
    "            self.network.add(BatchNormalization())\n",
    "        self.network.add(Dense(LOW_DIM, activation='linear', trainable=True))\n",
    "\n",
    "        self.network.summary()\n",
    "        \n",
    "        \n",
    "        # train only some layers\n",
    "        for layer in self.network.layers[:layer_nb]:\n",
    "            layer.trainable = False\n",
    "        for layer in self.network.layers[layer_nb:]:\n",
    "            layer.trainable = True\n",
    "        self.network.layers[-1].trainable = True\n",
    "\n",
    "        # compile the model\n",
    "\n",
    "\n",
    "        self.network.compile(optimizer=optim,\n",
    "                             loss='mse',\n",
    "                             metrics=['mae'])\n",
    "\n",
    "        self.network.summary()\n",
    "        csv_logger = CSVLogger(ROOTPATH+\"VGG16_\"+PB_FLAG+\"_\"+idOar+'_training.log')\n",
    "\n",
    "\n",
    "        checkpointer = ModelCheckpoint(filepath=ROOTPATH+\"VGG16_\"+PB_FLAG+\"_\"+idOar+\"_weights.hdf5\",\n",
    "                                       monitor='val_loss',\n",
    "                                       verbose=1,\n",
    "                                       save_weights_only=True,\n",
    "                                       save_best_only=True,\n",
    "                                       mode='min')\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=PATIENCE)\n",
    "\n",
    "        \n",
    "        class CheckNan(Callback):\n",
    "\n",
    "            def on_batch_end(self, batch, logs={}):\n",
    "                if math.isnan(logs.get('loss')):\n",
    "                    print(\"\\nReach a NAN\\n\")\n",
    "                    sys.exit()\n",
    "\n",
    "        # train the model on the new data for a few epochs\n",
    "        if epochLength<0:\n",
    "            spe=n_train\n",
    "        else:\n",
    "            spe=epochLength\n",
    "            \n",
    "        self.network.fit_generator(generator_training,\n",
    "                                   samples_per_epoch=spe,\n",
    "                                   nb_epoch=NB_EPOCH*int(n_train/(1.0*spe)),\n",
    "                                   verbose=1,\n",
    "                                   callbacks=[checkpointer,csv_logger,\n",
    "                                              early_stopping,CheckNan()],\n",
    "                                   validation_data=generator_val,\n",
    "                                   nb_val_samples=n_val)\n",
    "\n",
    "        \n",
    "        self.network.load_weights(ROOTPATH+\"VGG16_\"+PB_FLAG+\"_\"+idOar+\"_weights.hdf5\")\n",
    "        # self.network.save(ROOTPATH+\"VGG16_\"+PB_FLAG+\"_\"+idOar+\"_network.hdf5\")\n",
    "\n",
    "            \n",
    "        \n",
    "\n",
    "    def predict(self, generator, n_predict):\n",
    "        '''Generates output predictions for the input samples,\n",
    "           processing the samples in a batched way.\n",
    "        # Arguments\n",
    "            generator: input a generator object.\n",
    "            batch_size: integer.\n",
    "        # Returns\n",
    "            A Numpy array of predictions and GT.\n",
    "        '''\n",
    "        '''Extract VGG features and data targets from a generator'''\n",
    "    \n",
    "        i=0\n",
    "        Ypred=[]\n",
    "        Y=[]\n",
    "        for x,y in generator:\n",
    "            if i>=n_predict:\n",
    "                break\n",
    "            Ypred.extend(self.network.predict_on_batch(x))\n",
    "            Y.extend(y)\n",
    "            i+=len(y)\n",
    "\n",
    "        return np.asarray(Ypred), np.asarray(Y)\n",
    "\n",
    "   \n",
    "    def evaluate(self, (generator, n_eval),flagFile, l=WIDTH, pbFlag=PB_FLAG):\n",
    "        '''Computes the loss on some input data, batch by batch.\n",
    "        # Arguments\n",
    "            generator: input a generator object.\n",
    "            batch_size: integer. Number of samples per gradient update.\n",
    "        # Returns\n",
    "            Scalar test loss (if the model has no metrics)\n",
    "            or list of scalars (if the model computes other metrics).\n",
    "            The attribute `model.metrics_names` will give you\n",
    "            the display labels for the scalar outputs.\n",
    "        '''\n",
    "        \n",
    "        Ypred, Y = self.predict(generator, n_eval)\n",
    "\n",
    "        run_eval(Ypred, Y, l, pbFlag)\n",
    "        file = open(ROOTPATH+\"VGG_output\"+pbFlag+ \"_\"+str(idOar)+\"_\"+flagFile+\".txt\", \"w\")\n",
    "        file.write(\" \".join(sys.argv)+\"\\n\")\n",
    "        for y in Ypred-Y:\n",
    "            file.write(np.array_str(y, max_line_width=1000000)+\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    l2_Model = L2Model()\n",
    "\n",
    "    # t=[lambda x:random_rotation(x,2.0,row_index=2,col_index=3,channel_index=1),\n",
    "    #    lambda x:random_shift(x,0.03,0.03,row_index=2,col_index=3,channel_index=1),\n",
    "    #    lambda x:random_zoom(x,0.05,row_index=2,col_index=3,channel_index=1)]\n",
    "    # t=[lambda x:random_rotation(x,2.0,row_index=1,col_index=2,channel_index=0),\n",
    "    #    lambda x:random_shift(x,0.03,0.03,row_index=1,col_index=2,channel_index=0),\n",
    "    #    lambda x:random_zoom(x,[0.95,1.05],row_index=1,col_index=2,channel_index=0)]\n",
    "\n",
    "    (gen_training, N_train), (gen_val, N_val), (gen_test, N_test) = load_data_generator(ROOTPATH, train_txt, test_txt,validation=0.8,subsampling=ssRatio,batch_size=BATCH_SIZE)\n",
    "\n",
    "    l2_Model.fit((gen_training, N_train),(gen_val, N_val))\n",
    "\n",
    "    l2_Model.evaluate((gen_training, N_train),\"training\", 224)\n",
    "    l2_Model.evaluate((gen_val, N_val),\"validation\", 224)\n",
    "    l2_Model.evaluate((gen_test, N_test),\"test\", 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
