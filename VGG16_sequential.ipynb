{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-ff3dbd941183>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConvolution2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZeroPadding2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "'''VGG16 model for Keras.\n",
    "# Reference:\n",
    "- [Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/abs/1409.1556)\n",
    "'''\n",
    "\n",
    "# from __future__ import print_function\n",
    "# from __future__ import absolute_import\n",
    "\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Dropout, Activation\n",
    "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.utils.layer_utils import convert_all_kernels_in_model\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import backend as K\n",
    "import socket\n",
    "import os.path\n",
    "\n",
    "\n",
    "WEIGHTS_PATH = '../vgg16_weights_init.h5' #download this and put your PATH to weights here \n",
    "TF_WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5'\n",
    "\n",
    "\n",
    "\n",
    "# TH_WEIGHTS_PATH_DEEP_GLLIM = 'path/to/your_th_weights'\n",
    "# TF_WEIGHTS_PATH_DEEP_GLLIM = 'path/to/your_tf_weights'\n",
    "# TH_WEIGHTS_PATH_DEEP_GLLIM_PCA_BN = '/services/scratch/perception/dataBiwi/Deep_Gllim_pose86407_K2_weights.hdf5'\n",
    "\n",
    "def VGG16(weights='imagenet'):\n",
    "    '''Instantiate the VGG16 architecture,\n",
    "    optionally loading weights pre-trained\n",
    "    on ImageNet. Note that when using TensorFlow,\n",
    "    for best performance you should set\n",
    "    `image_dim_ordering=\"tf\"` in your Keras config\n",
    "    at ~/.keras/keras.json.\n",
    "    The model and the weights are compatible with both\n",
    "    TensorFlow and Theano. The dimension ordering\n",
    "    convention used by the model is the one\n",
    "    specified in your Keras config file.\n",
    "    # Arguments\n",
    "        include_top: whether to include the 3 fully-connected\n",
    "            layers at the top of the network.\n",
    "        weights: one of `deep_gllim` (fine tunned weights)\n",
    "            or \"imagenet\" (pre-training on ImageNet).\n",
    "    # Returns\n",
    "        A Keras model instance.\n",
    "    '''\n",
    "    # if weights not in {'imagenet', 'deep_gllim'}:\n",
    "    #     raise ValueError('The `weights` argument should be either '\n",
    "    #                      '`imagenet` (pre-training on ImageNet)'\n",
    "    #                      'or `deep_gllim` (fine tunned weights).')\n",
    "\n",
    "    # Determine proper input shape\n",
    "    if K.image_data_format() == 'th':\n",
    "        INPUT_SHAPE = (3, 224, 224)\n",
    "    else:\n",
    "        INPUT_SHAPE = (224, 224, 3)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1,1),input_shape=INPUT_SHAPE))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu', trainable=False))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu', trainable=False))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu', trainable=False))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu', trainable=False))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu', trainable=False))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu', trainable=False))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu', trainable=False))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu', trainable=False))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu', trainable=False))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu', trainable=False))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu', trainable=False))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu', trainable=False))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu', trainable=False))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "        \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='relu', trainable=True))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4096, activation='relu', trainable=True))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1000, activation='softmax', trainable=True))\n",
    "        \n",
    "    # load weights\n",
    "    if weights == 'imagenet':\n",
    "        if K.image_data_format() == 'th':\n",
    "            print(\"LOAD: \" + WEIGHTS_PATH)\n",
    "            weights_path = WEIGHTS_PATH\n",
    "            model.load_weights(weights_path)\n",
    "            model.pop() # remove softmax layer\n",
    "            model.pop() # remove dropout\n",
    "            if K.backend() == 'tensorflow':\n",
    "                warnings.warn('You are using the TensorFlow backend, yet you '\n",
    "                              'are using the Theano '\n",
    "                              'image dimension ordering convention '\n",
    "                              '(`image_dim_ordering=\"th\"`). '\n",
    "                              'For best performance, set '\n",
    "                              '`image_dim_ordering=\"tf\"` in '\n",
    "                              'your Keras config '\n",
    "                              'at ~/.keras/keras.json.')\n",
    "                convert_all_kernels_in_model(model)\n",
    "           \n",
    "        else:\n",
    "            weights_path = get_file('vgg16_weights_tf_dim_ordering_tf_kernels.h5',\n",
    "                                    TF_WEIGHTS_PATH,\n",
    "                                    cache_subdir='models')\n",
    "            model.load_weights(weights_path)\n",
    "            model.pop() # remove softmax layer\n",
    "            model.pop() # remove dropout\n",
    "            if K.backend() == 'theano':\n",
    "                convert_all_kernels_in_model(model)\n",
    "       \n",
    "         \n",
    "    elif weights == 'deep_gllim':\n",
    "        if K.image_data_format() == 'th':\n",
    "            weights_path = TH_WEIGHTS_PATH_DEEP_GLLIM\n",
    "            model.load_weights(weights_path)\n",
    "            model.pop() # remove softmax layer\n",
    "            model.pop() # remove dropout\n",
    "            if K.backend() == 'tensorflow':\n",
    "                warnings.warn('You are using the TensorFlow backend, yet you '\n",
    "                              'are using the Theano '\n",
    "                              'image dimension ordering convention '\n",
    "                              '(`image_dim_ordering=\"th\"`). '\n",
    "                              'For best performance, set '\n",
    "                              '`image_dim_ordering=\"tf\"` in '\n",
    "                              'your Keras config '\n",
    "                              'at ~/.keras/keras.json.')\n",
    "                convert_all_kernels_in_model(model)\n",
    "                \n",
    "        else:\n",
    "            weights_path = TF_WEIGHTS_PATH_DEEP_GLLIM\n",
    "            model.load_weights(weights_path)\n",
    "            model.pop() # remove softmax layer\n",
    "            model.pop() # remove dropout\n",
    "            if K.backend() == 'theano':\n",
    "                convert_all_kernels_in_model(model)\n",
    "    elif weights == 'deep_gllim_PCA_BN':\n",
    "        model.pop()  # remove softmax layer\n",
    "        model.pop()  # remove dropout\n",
    "        model.add(Dense(512, activation='linear', trainable=False))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        weights_path = TH_WEIGHTS_PATH_DEEP_GLLIM_PCA_BN \n",
    "        model.load_weights(weights_path)\n",
    "        model.pop()  # remove BN\n",
    "    return model\n",
    "\n",
    "def extract_features_generator(network, generator, size):\n",
    "    '''Extract VGG features from a generator'''\n",
    "    \n",
    "    print(\"Extracting features :\")\n",
    "    \n",
    "    features = network.predict_generator(generator, val_samples=size)\n",
    "    \n",
    "    return features\n",
    "\n",
    "def extract_features(network, x):\n",
    "    '''Extract VGG features from a generator'''\n",
    "    \n",
    "    print(\"Extracting features :\")\n",
    "    \n",
    "    features = network.predict(x, batch_size=64)\n",
    "    \n",
    "    return features\n",
    "\n",
    "def extract_XY_generator(network, generator, size):\n",
    "    '''Extract VGG features and data targets from a generator'''\n",
    "    \n",
    "    i=0\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    for x,y in generator:\n",
    "        X.extend(network.predict_on_batch(x))\n",
    "        Y.extend(y)\n",
    "        i+=len(y)\n",
    "        if i>=size:\n",
    "            break\n",
    "        \n",
    "    return np.asarray(X), np.asarray(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
