{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Create generators from dataset '''\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "HIGH_DIM = 512\n",
    "GLLIM_K = 1\n",
    "\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# Mode for the validation set for our mixture model\n",
    "\n",
    "def load_data_generator_List(rootpath, imIn, file_test, validation=1.0,subsampling=1.0,processingTarget=None,transform=[],outSize=(224,224),batch_size=BATCH_SIZE,shuffle=False):\n",
    "    ''' create generators from data'''\n",
    "\n",
    "    \n",
    "    def generator(rootpath, images):\n",
    "        \n",
    "        N=len(images)\n",
    "        nbatches=N/batch_size+1\n",
    "        if N%batch_size==0:\n",
    "            nbatches-=1\n",
    "        if shuffle:\n",
    "            random.shuffle(images)\n",
    "\n",
    "        i=0\n",
    "        while 1:\n",
    "            X, Y = get_xy_from_file(rootpath, images[i*batch_size:(i+1)*batch_size],processingTarget=processingTarget,transform=transform,outSize=outSize)\n",
    "            yield(X, Y)\n",
    "            i=i+1\n",
    "            if i>=nbatches:  # we shuffle the data when the end of the dataset is reached\n",
    "                i=0\n",
    "                random.shuffle(images)\n",
    "\n",
    "    imTest = open(rootpath+file_test, 'r').readlines()\n",
    "    gen_test = generator(rootpath, imTest)\n",
    "    test_size=len(imTest)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # we subsample the data if needed\n",
    "    if subsampling!=1.0:\n",
    "        im=imIn[0:int(subsampling*len(imIn))][:]\n",
    "    else:\n",
    "        im=imIn[:]\n",
    "        \n",
    "    if validation!=1.0:  # if we use a validation set\n",
    "        Ntot=len(im)\n",
    "        training_size = int(validation*len(im))\n",
    "        val_size = Ntot-training_size\n",
    "        \n",
    "        gen_train = generator(rootpath, im[:training_size])\n",
    "        gen_val = generator(rootpath, im[training_size:])\n",
    "\n",
    "        return (gen_train,training_size),(gen_val,val_size), (gen_test,test_size)\n",
    "    else:  # without validation set\n",
    "        gen_train = generator(rootpath, im)\n",
    "        training_size = len(im)\n",
    "     \n",
    "        return (gen_train,training_size), (gen_test,test_size)\n",
    "\n",
    "def load_data_generator(rootpath, file_train, file_test, validation=1.0,subsampling=1.0,processingTarget=None,transform=[],outSize=(224,224),batch_size=BATCH_SIZE,shuffle=False):\n",
    "    im = open(rootpath+file_train, 'r').readlines()\n",
    "    return load_data_generator_List(rootpath, im[:], file_test, validation,subsampling,processingTarget=processingTarget,transform=transform,outSize=outSize,batch_size=batch_size,shuffle=shuffle)\n",
    "\n",
    "def load_data_generator_List_simple(rootpath, imIn,transform=[],outSize=(224,224),batch_size=BATCH_SIZE,processingTarget=None,sample_weights=None):\n",
    "    ''' create generators from data'''\n",
    "\n",
    "    \n",
    "    def generator(rootpath, images):\n",
    "        \n",
    "        N=len(images)\n",
    "        nbatches=N/batch_size+1\n",
    "        if N%batch_size==0:\n",
    "            nbatches-=1\n",
    "        i=0\n",
    "        if sample_weights is not None:\n",
    "            rn= sample_weights[:]\n",
    "        while 1:\n",
    "\n",
    "            X, Y = get_xy_from_file(rootpath, images[i*batch_size:(i+1)*batch_size],processingTarget=processingTarget,transform=transform,outSize=outSize)\n",
    "            if sample_weights is None:\n",
    "                yield(X, Y)\n",
    "            else:\n",
    "                yield(X, Y,rn[i*batch_size:(i+1)*batch_size])\n",
    "            i=i+1\n",
    "            if i>=nbatches:  # we shuffle the data when the end of the dataset is reached\n",
    "                i=0\n",
    "                if sample_weights is None:\n",
    "                    random.shuffle(images)\n",
    "                else:\n",
    "                    c = zip(images,rn)\n",
    "                    np.random.shuffle(c)\n",
    "                    images = np.asarray([e[0] for e in c])\n",
    "                    rn = np.asarray([e[1] for e in c])\n",
    "\n",
    "                    \n",
    "\n",
    "    gen = generator(rootpath, imIn[:])\n",
    "    size=len(imIn)\n",
    "\n",
    "    return (gen,size)\n",
    "\n",
    "def load_data_generator_simple(rootpath, fileName, transform=[],outSize=(224,224),batch_size=BATCH_SIZE,processingTarget=None):\n",
    "    im = open(rootpath+fileName, 'r').readlines()\n",
    "    return load_data_generator_List_simple(rootpath, im[:],transform=transform,outSize=outSize,batch_size=batch_size,processingTarget=processingTarget)\n",
    "\n",
    "\n",
    "\n",
    "def applyTransform(x,transform):\n",
    "    for t in transform:\n",
    "        x=t(x)\n",
    "    return x\n",
    "\n",
    "    \n",
    "def get_xy_from_file(rootpath, images, processingTarget=None,transform=[],outSize=(224,224),batch_size=BATCH_SIZE):\n",
    "    '''Extract data arrays from text file'''\n",
    "    \n",
    "    X = np.zeros((len(images),3, outSize[0], outSize[1]), dtype=np.float32)\n",
    "    Y=[]\n",
    "\n",
    "    \n",
    "    for i,image in enumerate(images):\n",
    "        currentline=image.strip().split(\" \")\n",
    "        \n",
    "        imFile=currentline[0]\n",
    "        \n",
    "        X[i]=get_image_for_vgg(rootpath+imFile,transform,outSize)\n",
    "            \n",
    "        Y.append(np.asarray(map(lambda x: float(x),currentline[1:])))\n",
    "\n",
    "\n",
    "    if processingTarget:\n",
    "        Y=processingTarget(Y)\n",
    "\n",
    "    Y=np.squeeze(np.asarray(Y)).reshape((X.shape[0],len(Y[0])))\n",
    "    return (X,Y)\n",
    "\n",
    "def get_image_for_vgg(imName,transform=[],outSize=(224,224),batch_size=BATCH_SIZE):\n",
    "    '''Preprocess images as VGG inputs'''\n",
    "    im = (cv2.resize(cv2.imread(imName), (outSize[1],outSize[0]))).astype(np.float32)\n",
    "\n",
    "\n",
    "    # we substract the mean value of imagenet\n",
    "    if outSize==(224,224):\n",
    "        im[:,:,0] -= 103.939\n",
    "        im[:,:,1] -= 116.779\n",
    "        im[:,:,2] -= 123.68\n",
    "    im = im.transpose(2,0,1)\n",
    "    \n",
    "   \n",
    "    if transform:\n",
    "        im=applyTransform(im,transform)\n",
    "\n",
    "    im = np.expand_dims(im, axis=0)\n",
    "    \n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
